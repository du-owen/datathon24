{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":75012,"databundleVersionId":8339507,"sourceType":"competition"},{"sourceId":8248495,"sourceType":"datasetVersion","datasetId":4893860}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport ast\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-28T00:41:43.041363Z","iopub.execute_input":"2024-04-28T00:41:43.042362Z","iopub.status.idle":"2024-04-28T00:41:43.047299Z","shell.execute_reply.started":"2024-04-28T00:41:43.042325Z","shell.execute_reply":"2024-04-28T00:41:43.046184Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"# List all input files\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if not \"chart\" in filename:\n            print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2024-04-28T00:41:43.384698Z","iopub.execute_input":"2024-04-28T00:41:43.385398Z","iopub.status.idle":"2024-04-28T00:42:07.298506Z","shell.execute_reply.started":"2024-04-28T00:41:43.385360Z","shell.execute_reply":"2024-04-28T00:42:07.297652Z"},"trusted":true},"execution_count":135,"outputs":[{"name":"stdout","text":"/kaggle/input/croppedimages2/updated_data.csv\n/kaggle/input/think-cell-datathon/sample_submission.csv\n/kaggle/input/think-cell-datathon/val_and_test.csv\n/kaggle/input/think-cell-datathon/data_loading_example.ipynb\n/kaggle/input/think-cell-datathon/train.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_pie_data(filepath):\n    # Load data from CSV file into a DataFrame\n    data = pd.read_csv(filepath)\n\n    # Convert string representation of lists back to actual lists\n    list_data_features = [\"boxes\", \"start_angles\", \"end_angles\", \"angles\", \"percentages\"]\n    for column in list_data_features:\n        data[column] = data[column].apply(ast.literal_eval)\n\n    return data\n\ntrain_df = load_pie_data(\"/kaggle/input/croppedimages2/updated_data.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T00:42:07.300185Z","iopub.execute_input":"2024-04-28T00:42:07.300490Z","iopub.status.idle":"2024-04-28T00:42:09.253941Z","shell.execute_reply.started":"2024-04-28T00:42:07.300464Z","shell.execute_reply":"2024-04-28T00:42:09.253070Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"from torchvision.models import resnet18\n\nclass CenterCNN(nn.Module):\n    def __init__(self):\n        super(CenterCNN, self).__init__()\n        self.backbone = resnet18(weights=None)\n        self.backbone.fc = nn.Linear(512,2,bias=True)\n        self.backbone.train()\n    \n    def forward(self, x):\n        return self.backbone(x)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T00:42:09.255053Z","iopub.execute_input":"2024-04-28T00:42:09.255372Z","iopub.status.idle":"2024-04-28T00:42:09.261485Z","shell.execute_reply.started":"2024-04-28T00:42:09.255334Z","shell.execute_reply":"2024-04-28T00:42:09.260443Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport torchvision.transforms as transforms\nimport os\n\ndef transformImages(idx, train_df):\n    \n    chart_dict = train_df.loc[idx]\n    image_path = f\"/kaggle/input/croppedimages2/cropped_images/cropped_images/{chart_dict['filename']}\"\n    if os.path.exists(image_path):\n        image = Image.open(image_path).convert(\"RGB\")\n\n        transform = transforms.Compose([\n            transforms.Resize((256, 256)),  # Resize the image to 224x224\n            transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n        ])\n\n        scale_x = 256 / image.height\n        scale_y = 256 / image.width\n\n        kp = train_df.loc[idx][\"boxes\"][0][-2:]\n        kp[0] *= scale_x\n        kp[1] *= scale_y\n\n        image_tensor = transform(image)\n        kp = torch.tensor(kp)\n        return image_tensor, kp, scale_x, scale_y\n    \n    return None","metadata":{"execution":{"iopub.status.busy":"2024-04-28T00:42:09.263458Z","iopub.execute_input":"2024-04-28T00:42:09.263741Z","iopub.status.idle":"2024-04-28T00:42:09.275533Z","shell.execute_reply.started":"2024-04-28T00:42:09.263717Z","shell.execute_reply":"2024-04-28T00:42:09.274563Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader, random_split\n\nclass ImageDataset(Dataset):\n    def __init__(self, data, transform=None):\n        self.data = data\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        image_tensor, kp, scale_x, scale_y = transformImages(idx, self.data)\n        return {\"image\": image_tensor, \"keypoint\": kp, \"scale_x\": scale_x, \"scale_y\": scale_y}\n        \n\ndef train(train_dataset,val_dataset):\n    epochs = 30\n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n    \n    model = CenterCNN().to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n    \n    for epoch in range(epochs):\n        print(\"epoch\", epoch)\n        avg_loss = 0\n        for idx, batch in enumerate(dataloader):\n            model.train()\n            optimizer.zero_grad()\n            labels = batch[\"keypoint\"].to(device)\n            preds = model(batch[\"image\"].to(device))\n            criterion = nn.MSELoss()\n            loss = criterion(preds, labels)\n            loss.backward()\n            optimizer.step()\n            \n            avg_loss += loss\n        \n        if val_dataset:\n            validate(val_dataset, model, device)\n            \n        avg_loss /= len(dataloader)\n        print(\"avg epoch loss:\", avg_loss)\n        \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-04-28T00:42:09.276774Z","iopub.execute_input":"2024-04-28T00:42:09.277105Z","iopub.status.idle":"2024-04-28T00:42:09.289388Z","shell.execute_reply.started":"2024-04-28T00:42:09.277075Z","shell.execute_reply":"2024-04-28T00:42:09.288509Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"def unresize(kp, scale_x, scale_y):\n    return torch.tensor([kp[0] / scale_x, kp[1] / scale_y],dtype=torch.float32)\n\ndef validate(val_dataset, model, device):\n\n    dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n    model.eval()\n    avg_warped_loss = 0\n    avg_true_error = 0\n    with torch.no_grad():\n        for idx, batch in enumerate(dataloader):\n            labels = batch[\"keypoint\"].to(device)\n            preds = model(batch[\"image\"].to(device))\n            criterion = nn.MSELoss()\n            loss = criterion(preds, labels)\n            avg_warped_loss += loss\n            pred_og = unresize(preds[0], batch[\"scale_x\"][0], batch[\"scale_y\"][0])\n            label_og = unresize(labels[0], batch[\"scale_x\"][0], batch[\"scale_y\"][0])\n            avg_true_error += torch.sqrt(torch.sum((pred_og - label_og)**2))\n        \n    avg_warped_loss /= len(dataloader)\n    avg_true_error /= len(dataloader)\n    print(\"avg warped loss\", avg_warped_loss)\n    print(\"avg true error\", avg_true_error)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T00:42:09.290721Z","iopub.execute_input":"2024-04-28T00:42:09.291056Z","iopub.status.idle":"2024-04-28T00:42:09.303052Z","shell.execute_reply.started":"2024-04-28T00:42:09.291026Z","shell.execute_reply":"2024-04-28T00:42:09.302182Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"dataset = ImageDataset(train_df)\n# train_size = int(0.8*len(dataset))\n# valid_size = len(dataset) - train_size\n# train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\nmodel = train(dataset, None)\n\npath = \"/kaggle/working/model_new.ckpt\"\n\ntorch.save(model.state_dict(), path)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T00:47:53.120581Z","iopub.execute_input":"2024-04-28T00:47:53.121513Z","iopub.status.idle":"2024-04-28T01:20:51.965423Z","shell.execute_reply.started":"2024-04-28T00:47:53.121474Z","shell.execute_reply":"2024-04-28T01:20:51.964229Z"},"trusted":true},"execution_count":142,"outputs":[{"name":"stdout","text":"epoch 0\navg epoch loss: tensor(854.8578, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 1\navg epoch loss: tensor(166.7605, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 2\navg epoch loss: tensor(167.3474, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 3\navg epoch loss: tensor(166.3873, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 4\navg epoch loss: tensor(165.7303, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 5\navg epoch loss: tensor(164.6215, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 6\navg epoch loss: tensor(163.0002, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 7\navg epoch loss: tensor(161.7993, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 8\navg epoch loss: tensor(161.9917, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 9\navg epoch loss: tensor(161.3918, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 10\navg epoch loss: tensor(159.5151, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 11\navg epoch loss: tensor(157.6417, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 12\navg epoch loss: tensor(154.8330, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 13\navg epoch loss: tensor(155.1836, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 14\navg epoch loss: tensor(151.5803, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 15\navg epoch loss: tensor(148.0524, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 16\navg epoch loss: tensor(144.1070, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 17\navg epoch loss: tensor(140.6546, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 18\navg epoch loss: tensor(135.7760, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 19\navg epoch loss: tensor(131.8229, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 20\navg epoch loss: tensor(127.9435, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 21\navg epoch loss: tensor(125.5753, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 22\navg epoch loss: tensor(116.6192, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 23\navg epoch loss: tensor(116.4431, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 24\navg epoch loss: tensor(113.0630, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 25\navg epoch loss: tensor(108.8930, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 26\navg epoch loss: tensor(102.5759, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 27\navg epoch loss: tensor(97.8920, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 28\navg epoch loss: tensor(95.1283, device='cuda:0', grad_fn=<DivBackward0>)\nepoch 29\navg epoch loss: tensor(89.9227, device='cuda:0', grad_fn=<DivBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"import csv\n\nclass TestDataset:\n    def __init__(self, start, end):\n        self.start = start\n        self.end = end\n    def __len__(self):\n        return self.end-self.start\n    def __getitem__(self,idx):\n        idx = self.start + idx\n        path = f\"/kaggle/input/croppedimages2/cropped_images (2)/cropped_images/chart_{idx}.png\"\n        image = Image.open(path).convert(\"RGB\")\n\n        transform = transforms.Compose([\n            transforms.Resize((256, 256)),  # Resize the image to 224x224\n            transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n        ])\n\n        scale_x = 256 / image.width\n        scale_y = 256 / image.height\n        \n        image_tensor = transform(image)\n        return {\"image\": image_tensor, \"scale_x\": scale_x, \"scale_y\": scale_y}\n        \ndef test(model, mode):\n    if mode == \"val\":\n        start = 10000\n        end = 10005\n    elif mode == \"test\":\n        start = 20000\n        end = 30000\n        \n    model.eval()\n    model.cpu()\n    \n    output = []\n    dataset = TestDataset(start, end)\n    dataloader = DataLoader(dataset, batch_size=1,shuffle=False)\n    \n    for idx, batch in enumerate(dataloader, start=10000):\n        image_tensor = batch[\"image\"][0]\n        inputs = torch.unsqueeze(image_tensor,0)\n        pred = model(inputs)\n        \n        pred = pred[0]\n        scale_x = batch[\"scale_x\"][0]\n        scale_y = batch[\"scale_y\"][0]\n        \n        pred_unwarp = [idx, (pred[0]/scale_x).item(), (pred[1]/scale_y).item()]\n        \n        output.append(pred_unwarp)\n        \n    csv_file = '{}_outputs_new.csv'.format(mode)\n\n    with open(csv_file, 'w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['id', 'x', 'y'])  # Write header\n        writer.writerows(output)  # Write test outputs\n\ntest(model,\"val\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T23:50:37.574756Z","iopub.execute_input":"2024-04-27T23:50:37.575211Z","iopub.status.idle":"2024-04-27T23:50:37.844676Z","shell.execute_reply.started":"2024-04-27T23:50:37.575179Z","shell.execute_reply":"2024-04-27T23:50:37.843619Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"idx = 10001\n\npath = f\"/kaggle/input/croppedimages2/cropped_images (2)/cropped_images/chart_{idx}.png\"\nimage = Image.open(path).convert(\"RGB\")\ntransform = transforms.Compose([\n            transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n        ])\nimage = transform(image)\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 5))\n\naxes[0].imshow(image[0])\naxes[0].set_title('Image')\naxes[0].axis('off')\n\ncsv_file = '/kaggle/working/val_outputs_new.csv'\n\ndf = pd.read_csv(csv_file)\n\nind = 4\nkp = [df[\"x\"][ind],df[\"y\"][ind]]\nprint(kp)\n\naxes[0].scatter(224, 221, color='red', marker='o', s=10)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-28T00:47:47.172516Z","iopub.status.idle":"2024-04-28T00:47:47.172843Z","shell.execute_reply.started":"2024-04-28T00:47:47.172677Z","shell.execute_reply":"2024-04-28T00:47:47.172690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}